# -*- coding: utf-8 -*-
"""Image segmentation humans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yqQ-8ky1ulsu5sP9r6xH9BEJ_N-UonwV
"""

!pip install -q kaggle
from google.colab import files

# Upload your kaggle.json (Kaggle API key)
files.upload()

# Set up Kaggle API credentials
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d tapakah68/segmentation-full-body-mads-dataset
!unzip segmentation-full-body-mads-dataset.zip -d mads_dataset

!pip uninstall -y keras
!pip uninstall -y tensorflow
!pip install tensorflow==2.18.0
!pip install keras

import os
import pandas as pd
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import Sequence
import matplotlib.pyplot as plt

# Load df.csv
df = pd.read_csv('mads_dataset/df.csv')

# Base folder where 'images' and 'masks' directories exist
base_path = 'mads_dataset/segmentation_full_body_mads_dataset_1192_img/segmentation_full_body_mads_dataset_1192_img'

# Join full paths
image_paths = [os.path.join(base_path, path) for path in df['images']]
mask_paths = [os.path.join(base_path, path) for path in df['masks']]

# Filter only existing paths
valid_image_paths, valid_mask_paths = [], []
for img, mask in zip(image_paths, mask_paths):
    if os.path.exists(img) and os.path.exists(mask):
        valid_image_paths.append(img)
        valid_mask_paths.append(mask)
    else:
        print(f"[SKIPPED] {img} or {mask} missing")

class DataGenerator(Sequence):
    def __init__(self, image_paths, mask_paths, batch_size=8, image_size=(256, 256)):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.batch_size = batch_size
        self.image_size = image_size
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.image_paths) / self.batch_size))

    def on_epoch_end(self):
        self.indices = np.arange(len(self.image_paths))
        np.random.shuffle(self.indices)

    def __getitem__(self, index):
        idxs = self.indices[index * self.batch_size:(index + 1) * self.batch_size]
        batch_images, batch_masks = [], []

        for i in idxs:
            img = cv2.imread(self.image_paths[i])
            mask = cv2.imread(self.mask_paths[i], cv2.IMREAD_GRAYSCALE)

            if img is None or mask is None:
                continue

            img = cv2.resize(img, self.image_size) / 255.0
            mask = cv2.resize(mask, self.image_size)
            mask = (mask > 127).astype(np.float32)
            mask = np.expand_dims(mask, axis=-1)

            batch_images.append(img)
            batch_masks.append(mask)

        if len(batch_images) == 0:
            return self.__getitem__((index + 1) % self.__len__())

        return np.array(batch_images), np.array(batch_masks)

def build_light_unet(input_shape=(256, 256, 3)):
    def conv_block(x, filters):
        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)
        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)
        return x

    def encoder_block(x, filters):
        f = conv_block(x, filters)
        p = layers.MaxPooling2D((2, 2))(f)
        return f, p

    def decoder_block(x, skip, filters):
        x = layers.UpSampling2D((2, 2))(x)
        x = layers.Concatenate()([x, skip])
        x = conv_block(x, filters)
        return x

    inputs = layers.Input(shape=input_shape)

    f1, p1 = encoder_block(inputs, 32)
    f2, p2 = encoder_block(p1, 64)
    f3, p3 = encoder_block(p2, 128)
    f4, p4 = encoder_block(p3, 256)

    b = layers.Conv2D(256, 3, activation='relu', padding='same')(p4)

    d1 = decoder_block(b, f4, 256)
    d2 = decoder_block(d1, f3, 128)
    d3 = decoder_block(d2, f2, 64)
    d4 = decoder_block(d3, f1, 32)

    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(d4)
    return models.Model(inputs, outputs)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Callbacks
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

checkpoint = ModelCheckpoint(
    "best_unet_mads.h5",
    save_best_only=True,
    monitor='val_loss',
    mode='min',
    verbose=1
)

# Build and compile model
model = build_light_unet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train model
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=20,  # Safe max with early stopping
    callbacks=[early_stopping, checkpoint]
)

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title("Training Curve")
plt.xlabel("Epoch")
plt.ylabel("Loss / Accuracy")
plt.grid(True)
plt.show()

# Load legacy model
model = tf.keras.models.load_model("best_unet_mads.h5")

# Save in Keras 3 format (file or directory)
model.save("best_unet_mads.keras")  # Recommended
# or:
# model.save("best_unet_mads")  # as folder

from google.colab import files
from PIL import Image
import io

# Upload any image file (JPG, PNG)
uploaded = files.upload()

# Get the filename
file_name = next(iter(uploaded))

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load image
img = Image.open(file_name).convert("RGB")
img_np = np.array(img)

# Resize for model
img_resized = cv2.resize(img_np, (256, 256)) / 255.0
input_tensor = np.expand_dims(img_resized, axis=0)

# Predict
pred = model.predict(input_tensor)[0]
pred_mask = (pred.squeeze() > 0.5).astype(np.uint8) * 255

# Resize mask to original image size
pred_mask_resized = cv2.resize(pred_mask, (img_np.shape[1], img_np.shape[0]))

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.imshow(img_np)
plt.title("Original Image")

plt.subplot(1, 2, 2)
plt.imshow(pred_mask_resized, cmap="gray")
plt.title("Predicted Mask")

plt.show()